{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f50cc59efaf04509b49e8cf633c66ead": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fcf5b6cde48640fe845fd92aa1470777",
              "IPY_MODEL_7ad33f29b4d3460389670ab88006a3ea",
              "IPY_MODEL_9652515bd7084327878af446ba10c0ee"
            ],
            "layout": "IPY_MODEL_112e5d8dbbd94172ba95294f3b92239b"
          }
        },
        "fcf5b6cde48640fe845fd92aa1470777": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba0ea278bd294fa5847a091274dac2fc",
            "placeholder": "​",
            "style": "IPY_MODEL_c88b07741c064fa0a7fcaf49b976ebe4",
            "value": "Map: 100%"
          }
        },
        "7ad33f29b4d3460389670ab88006a3ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eedc873235374bf9a212e09ffa92254d",
            "max": 16407,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_01f3b1dd3475448cbc7dc9e4af584371",
            "value": 16407
          }
        },
        "9652515bd7084327878af446ba10c0ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_873d1183ab3d414882af1fa042a33c40",
            "placeholder": "​",
            "style": "IPY_MODEL_aabf50d23dc44bbd901ce88c0fe8459a",
            "value": " 16407/16407 [00:00&lt;00:00, 40053.32 examples/s]"
          }
        },
        "112e5d8dbbd94172ba95294f3b92239b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba0ea278bd294fa5847a091274dac2fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c88b07741c064fa0a7fcaf49b976ebe4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eedc873235374bf9a212e09ffa92254d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01f3b1dd3475448cbc7dc9e4af584371": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "873d1183ab3d414882af1fa042a33c40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aabf50d23dc44bbd901ce88c0fe8459a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a2e76d42b1d47d58c9a031a6f4239bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_90f95f3396d14996a2e2e3a53a6462cd",
              "IPY_MODEL_bf3020b286224282af83064a4113e82f",
              "IPY_MODEL_3f388e70ce6c45d089e9b9cc3b4438ec"
            ],
            "layout": "IPY_MODEL_f8114af936454753b1472e656b01d5cb"
          }
        },
        "90f95f3396d14996a2e2e3a53a6462cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bdd665a693d64b1faf9580151c4e7588",
            "placeholder": "​",
            "style": "IPY_MODEL_d52f244607b54c31a8f82c3e19a4fd4d",
            "value": "Unsloth: Tokenizing [&quot;text&quot;] (num_proc=4): 100%"
          }
        },
        "bf3020b286224282af83064a4113e82f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8fdd9f83f5a4dd1a3a24c6607a869b5",
            "max": 1544,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_97263e1b78c645c69eb1ec239e382e37",
            "value": 1544
          }
        },
        "3f388e70ce6c45d089e9b9cc3b4438ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_965952a4113d4445beb3fc27a6c18ca9",
            "placeholder": "​",
            "style": "IPY_MODEL_eea694fd62e345f4ac1142e2c5603931",
            "value": " 1544/1544 [00:05&lt;00:00, 450.77 examples/s]"
          }
        },
        "f8114af936454753b1472e656b01d5cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdd665a693d64b1faf9580151c4e7588": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d52f244607b54c31a8f82c3e19a4fd4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8fdd9f83f5a4dd1a3a24c6607a869b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97263e1b78c645c69eb1ec239e382e37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "965952a4113d4445beb3fc27a6c18ca9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eea694fd62e345f4ac1142e2c5603931": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SameenYounas1/123/blob/main/Medical_Finetuning_With_Qlora_Using_Unsloth.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqLP5FjepuoE",
        "outputId": "c28b5e65-4312-4fcd-a417-18851e28145b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Jan 29 18:21:47 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   77C    P0             32W /   70W |    2652MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Unsloth and its dependencies for Colab\n",
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "!pip install --no-deps \"xformers<0.0.29\" trl peft accelerate bitsandbytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgXPkU7u6WzS",
        "outputId": "4b572700-2231-4564-f289-e64bc0aa513e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unsloth@ git+https://github.com/unslothai/unsloth.git (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-ym5yt4c7/unsloth_8ea1dcf8804f46529a9972cc2210f73f\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-ym5yt4c7/unsloth_8ea1dcf8804f46529a9972cc2210f73f\n",
            "  Resolved https://github.com/unslothai/unsloth.git to commit e51d3ea2e498fc893770d92ca6727bd113918480\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: unsloth_zoo>=2026.1.4 in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2026.1.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (25.0)\n",
            "Requirement already satisfied: tyro in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.0.5)\n",
            "Requirement already satisfied: transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,!=4.57.4,!=4.57.5,<=4.57.6,>=4.51.3 in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.57.6)\n",
            "Requirement already satisfied: datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1 in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.3.0)\n",
            "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.2.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (5.9.5)\n",
            "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.46.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.0.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (5.29.5)\n",
            "Requirement already satisfied: huggingface_hub>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.36.0)\n",
            "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.9)\n",
            "Requirement already satisfied: bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5 in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.49.1)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (5.2.1)\n",
            "Requirement already satisfied: torch<3,>=2.3 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.9.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (23.0.0)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.32.4)\n",
            "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.28.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2025.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.34.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.34.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.2.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,!=4.57.4,!=4.57.5,<=4.57.6,>=4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,!=4.57.4,!=4.57.5,<=4.57.6,>=4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,!=4.57.4,!=4.57.5,<=4.57.6,>=4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.7.0)\n",
            "Requirement already satisfied: torchao>=0.13.0 in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2026.1.4->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.15.0)\n",
            "Requirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2026.1.4->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.5.0)\n",
            "Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2026.1.4->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.12.0)\n",
            "Requirement already satisfied: trl!=0.19.0,<=0.24.0,>=0.18.2 in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2026.1.4->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.24.0)\n",
            "Requirement already satisfied: peft!=0.11.0,>=0.18.0 in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2026.1.4->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.18.1)\n",
            "Requirement already satisfied: cut_cross_entropy in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2026.1.4->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (25.1.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2026.1.4->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (11.3.0)\n",
            "Requirement already satisfied: msgspec in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2026.1.4->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.20.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.16.3)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.17.0)\n",
            "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.4.4)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.13.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.12.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.16.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.5.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.11.1.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2025.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.3)\n",
            "Requirement already satisfied: xformers<0.0.29 in /usr/local/lib/python3.12/dist-packages (0.0.28.post3)\n",
            "Requirement already satisfied: trl in /usr/local/lib/python3.12/dist-packages (0.24.0)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.18.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.12/dist-packages (0.49.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wO6GPsjb5Yxt",
        "outputId": "7ba5d099-bd3a-4551-f464-3b268ff9484d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "# This downloads the MedQuAD CSV from a reliable Hugging Face repository\n",
        "REPO_ID = \"keivalya/MedQuad-MedicalQnADataset\"\n",
        "FILENAME = \"medDataset_processed.csv\"\n",
        "\n",
        "# Download and rename it to medquad.csv\n",
        "dataset_path = hf_hub_download(repo_id=REPO_ID, filename=FILENAME, repo_type=\"dataset\")\n",
        "df = pd.read_csv(dataset_path)\n",
        "df.to_csv(\"medquad.csv\", index=False)\n",
        "\n",
        "print(\"medquad.csv is now ready in your Colab files!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RdGTbnl5GRf",
        "outputId": "daa72fd3-4ec8-475e-ac2d-c15b570d0eea"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "medquad.csv is now ready in your Colab files!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 1: Install Unsloth + dependencies\n",
        "!pip install -q unsloth\n",
        "!pip install -q transformers datasets accelerate bitsandbytes peft trl\n"
      ],
      "metadata": {
        "id": "SSfs3eWov3CX"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"Torch:\", torch.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "print(\"GPU:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"None\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1H7KZja-xCxW",
        "outputId": "1c1382eb-f9f8-4ced-a050-04306c6fa5da"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch: 2.9.0+cu126\n",
            "CUDA available: True\n",
            "GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import unsloth\n",
        "print(\"Unsloth OK\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVYlvyONxTOJ",
        "outputId": "28f6d7d0-bf06-4849-c829-24d04ba1fb40"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "\n",
        "# Unique Prompt Style\n",
        "alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "You are a Clinical Data Specialist. Provide a technical summary from the MedQuAD dataset for the medical inquiry below.\n",
        "\n",
        "### Question:\n",
        "{}\n",
        "\n",
        "### Answer:\n",
        "{}\"\"\"\n",
        "\n",
        "# 1. Load the CSV\n",
        "df = pd.read_csv(\"medquad.csv\")\n",
        "\n",
        "# 2. Match your specific column names (Question and Answer)\n",
        "# We use .str.strip() just in case there are hidden spaces\n",
        "df = df[[\"Question\", \"Answer\"]].dropna()\n",
        "\n",
        "# 3. Convert to HuggingFace Dataset\n",
        "dataset = Dataset.from_pandas(df)\n",
        "\n",
        "def formatting_prompts_func(examples):\n",
        "    # Match the capitalized names here as well\n",
        "    inputs       = examples[\"Question\"]\n",
        "    outputs      = examples[\"Answer\"]\n",
        "    texts = []\n",
        "    for input_text, output_text in zip(inputs, outputs):\n",
        "        text = alpaca_prompt.format(input_text, output_text)\n",
        "        texts.append(text)\n",
        "    return { \"text\" : texts, }\n",
        "\n",
        "dataset = dataset.map(formatting_prompts_func, batched = True,)\n",
        "print(f\"Dataset formatted for training! 🧬 Rows: {len(df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "f50cc59efaf04509b49e8cf633c66ead",
            "fcf5b6cde48640fe845fd92aa1470777",
            "7ad33f29b4d3460389670ab88006a3ea",
            "9652515bd7084327878af446ba10c0ee",
            "112e5d8dbbd94172ba95294f3b92239b",
            "ba0ea278bd294fa5847a091274dac2fc",
            "c88b07741c064fa0a7fcaf49b976ebe4",
            "eedc873235374bf9a212e09ffa92254d",
            "01f3b1dd3475448cbc7dc9e4af584371",
            "873d1183ab3d414882af1fa042a33c40",
            "aabf50d23dc44bbd901ce88c0fe8459a"
          ]
        },
        "id": "JkX5boewxwbw",
        "outputId": "8bbf14e5-bd35-4977-ab3e-52b5ff6dbb0a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/16407 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f50cc59efaf04509b49e8cf633c66ead"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset formatted for training! 🧬 Rows: 16407\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df = df.sample(3000, random_state=42)\n",
        "\n",
        "\n",
        "df = df[(df[\"Question\"].str.len() < 300) & (df[\"Answer\"].str.len() < 900)]\n",
        "print(\"After filter:\", len(df))\n",
        "\n",
        "def format_example(q, a):\n",
        "    return f\"\"\"### Instruction:\n",
        "You are a helpful medical assistant. Answer clearly and safely.\n",
        "\n",
        "### Question:\n",
        "{q}\n",
        "\n",
        "### Answer:\n",
        "{a}\"\"\"\n",
        "\n",
        "texts = [format_example(q,a) for q,a in zip(df[\"Question\"], df[\"Answer\"])]\n",
        "\n",
        "dataset = Dataset.from_dict({\"text\": texts})\n",
        "split = dataset.train_test_split(test_size=0.05, seed=42)\n",
        "train_ds, test_ds = split[\"train\"], split[\"test\"]\n",
        "\n",
        "print(train_ds, test_ds)\n",
        "print(train_ds[0][\"text\"][:400])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHJhn9evyNQf",
        "outputId": "098b56ad-3977-4760-bda5-04e539f019a7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After filter: 1544\n",
            "Dataset({\n",
            "    features: ['text'],\n",
            "    num_rows: 1466\n",
            "}) Dataset({\n",
            "    features: ['text'],\n",
            "    num_rows: 78\n",
            "})\n",
            "### Instruction:\n",
            "You are a helpful medical assistant. Answer clearly and safely.\n",
            "\n",
            "### Question:\n",
            "What are the symptoms of Hendra Virus Disease (HeV) ?\n",
            "\n",
            "### Answer:\n",
            "After an incubation of 9-16 days, infection with Hendra virus can lead to respiratory illness with severe flu-like signs and symptoms. In some cases, illness may progress to encephalitis. \n",
            "                \n",
            "Although infection with Hendra \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "\n",
        "# CHANGE THIS TO 2048\n",
        "max_seq_length = 2048\n",
        "dtype = None\n",
        "load_in_4bit = True\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/llama-3.2-3b-bnb-4bit\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        ")\n",
        "\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16,\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0,\n",
        "    bias = \"none\",\n",
        "    use_gradient_checkpointing = \"unsloth\",\n",
        ")\n",
        "print(\"Model updated to 2048 length! ✅\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ba-V2yihzSvu",
        "outputId": "26be8be9-480b-45fc-bf1a-1a0b5a242b42"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2026.1.4: Fast Llama patching. Transformers: 4.57.6.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.9.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.5.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = None. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "Model updated to 2048 length! ✅\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "from unsloth import is_bfloat16_supported\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = dataset, # FIXED: Changed from train_ds to dataset\n",
        "    dataset_text_field = \"text\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dataset_num_proc = 2,\n",
        "    packing = False,\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = 2,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        warmup_steps = 5,\n",
        "        max_steps = 60, # 60 steps is perfect for a fast, successful demo\n",
        "        learning_rate = 2e-4,\n",
        "        fp16 = not is_bfloat16_supported(),\n",
        "        bf16 = is_bfloat16_supported(),\n",
        "        logging_steps = 1,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 3407,\n",
        "        output_dir = \"outputs\",\n",
        "    ),\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8a2e76d42b1d47d58c9a031a6f4239bc",
            "90f95f3396d14996a2e2e3a53a6462cd",
            "bf3020b286224282af83064a4113e82f",
            "3f388e70ce6c45d089e9b9cc3b4438ec",
            "f8114af936454753b1472e656b01d5cb",
            "bdd665a693d64b1faf9580151c4e7588",
            "d52f244607b54c31a8f82c3e19a4fd4d",
            "b8fdd9f83f5a4dd1a3a24c6607a869b5",
            "97263e1b78c645c69eb1ec239e382e37",
            "965952a4113d4445beb3fc27a6c18ca9",
            "eea694fd62e345f4ac1142e2c5603931"
          ]
        },
        "id": "p-l-qDvDz_aQ",
        "outputId": "156f2626-f2dd-4321-b671-f9b1652c8b97"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Unsloth: Tokenizing [\"text\"] (num_proc=4):   0%|          | 0/1544 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8a2e76d42b1d47d58c9a031a6f4239bc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 1,544 | Num Epochs = 1 | Total steps = 60\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
            " \"-____-\"     Trainable parameters = 24,313,856 of 3,237,063,680 (0.75% trained)\n",
            "wandb: (1) Create a W&B account\n",
            "wandb: (2) Use an existing W&B account\n",
            "wandb: (3) Don't visualize my results\n",
            "wandb: Enter your choice:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "wandb: You chose \"Don't visualize my results\"\n",
            "wandb: Using W&B in offline mode.\n",
            "wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.24.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "W&B syncing is set to <code>`offline`<code> in this directory. Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing.<br>Run data is saved locally in <code>/content/wandb/offline-run-20260129_183051-26er8myk</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "wandb: Detected [huggingface_hub.inference, openai] in use.\n",
            "wandb: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.\n",
            "wandb: For more information, check out the docs at: https://weave-docs.wandb.ai/\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [60/60 01:44, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.076000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.125500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.175100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.048300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.947800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.945300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.676400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.609900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.449700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.393500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.296000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.300500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>1.235700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>1.116000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>1.266300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>1.418900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>1.270400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>1.237300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>1.400800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.364000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.902300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.875400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>1.196000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>1.022900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>1.050700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>1.347000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>1.228900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>1.117500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>1.160500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.272800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>1.184900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>1.157900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>1.177600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>1.286100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>1.244200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.996400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>1.296000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>1.129100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.931500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.826200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>1.110300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>1.387600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.934600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.921900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>1.027300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>1.324700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>1.098300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>1.248200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.991600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.189100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>1.064500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>1.045800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>0.978900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>1.319700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>1.194700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>1.018400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>0.944400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>1.300400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>0.977400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.877000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "wandb: WARNING URL not available in offline run\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>train/grad_norm</td><td>▃▂▂▆▅▅█▃▃▃▁▂▃▁▃▃▃▃▄▂▂▁▁▅▂▂▁▂▃▂▃▃▁▃▁▂▂▄▂▂</td></tr><tr><td>train/learning_rate</td><td>▂▅███▇▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁</td></tr><tr><td>train/loss</td><td>▇██▇▇▅▄▄▃▂▄▃▃▄▄▁▃▂▄▂▃▃▃▃▃▃▂▁▁▁▂▃▂▃▂▂▃▃▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>total_flos</td><td>1360780091252736.0</td></tr><tr><td>train/epoch</td><td>0.31088</td></tr><tr><td>train/global_step</td><td>60</td></tr><tr><td>train/grad_norm</td><td>0.49025</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.877</td></tr><tr><td>train_loss</td><td>1.26186</td></tr><tr><td>train_runtime</td><td>138.9473</td></tr><tr><td>train_samples_per_second</td><td>3.455</td></tr><tr><td>train_steps_per_second</td><td>0.432</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "You can sync this run to the cloud by running:<br><code>wandb sync /content/wandb/offline-run-20260129_183051-26er8myk<code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/offline-run-20260129_183051-26er8myk/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=60, training_loss=1.26186470190684, metrics={'train_runtime': 138.9473, 'train_samples_per_second': 3.455, 'train_steps_per_second': 0.432, 'total_flos': 1360780091252736.0, 'train_loss': 1.26186470190684, 'epoch': 0.31088082901554404})"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"medquad_lora\")\n",
        "tokenizer.save_pretrained(\"medquad_lora\")\n",
        "print(\"Saved\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5hzpnyW6n8u",
        "outputId": "1c6e2bc7-cb5f-4ef7-c2ca-318d481fc967"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FastLanguageModel.for_inference(model)\n",
        "\n",
        "prompt = \"\"\"### Instruction:\n",
        "You are a helpful medical assistant. Answer clearly and safely.\n",
        "\n",
        "### Question:\n",
        "What is hypertension?\n",
        "\n",
        "### Answer:\n",
        "\"\"\"\n",
        "\n",
        "inputs = tokenizer([prompt], return_tensors=\"pt\").to(\"cuda\")\n",
        "out = model.generate(**inputs, max_new_tokens=120)\n",
        "print(tokenizer.decode(out[0], skip_special_tokens=True))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZTpqHUV6ryn",
        "outputId": "7b428dbd-d530-434b-b4a4-d8b1e932724f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Instruction:\n",
            "You are a helpful medical assistant. Answer clearly and safely.\n",
            "\n",
            "### Question:\n",
            "What is hypertension?\n",
            "\n",
            "### Answer:\n",
            "Hypertension is a medical condition in which the blood pressure in the arteries is higher than normal. Blood pressure is the force of blood pushing against artery walls as the heart pumps. When blood pressure is too high, it may damage the heart, brain, kidneys, and eyes. Hypertension is a \"silent killer\" because it often has no warning signs or symptoms.  High blood pressure is called \"the silent killer\" because it often has no warning signs or symptoms.  Most people with high blood pressure have no symptoms. However, high blood pressure can cause:  Heart attack or\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "\n",
        "FastLanguageModel.for_inference(model)\n",
        "\n",
        "prompt = \"\"\"### Instruction:\n",
        "You are a helpful medical assistant. Answer clearly and safely.\n",
        "\n",
        "### Question:\n",
        "What causes glaucoma?\n",
        "\n",
        "### Answer:\n",
        "\"\"\"\n",
        "\n",
        "inputs = tokenizer([prompt], return_tensors=\"pt\").to(\"cuda\")\n",
        "out = model.generate(**inputs, max_new_tokens=160, do_sample=True, temperature=0.7)\n",
        "print(tokenizer.decode(out[0], skip_special_tokens=True))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsTKa6bO7pgI",
        "outputId": "eaddd874-9c6e-4177-cdea-e2eb55d3c79d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Instruction:\n",
            "You are a helpful medical assistant. Answer clearly and safely.\n",
            "\n",
            "### Question:\n",
            "What causes glaucoma?\n",
            "\n",
            "### Answer:\n",
            "Glaucoma is a group of eye diseases that damage the optic nerve. The optic nerve is the part of the eye that carries information from the eye to the brain. The optic nerve fibers are responsible for sending visual information to the brain. As the fibers become damaged, the quality of vision decreases. The damage to the optic nerve causes tunnel vision, which is the loss of peripheral (side) vision. If left untreated, glaucoma can lead to total blindness.  Glaucoma can be caused by several factors. These factors include genetics, age, and other health problems.  Many people with glaucoma have no symptoms. For this reason, it is important to have regular eye examinations. If glaucoma is caught early, it can be treated effectively.  Some eye diseases can\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ask(q):\n",
        "    prompt = f\"\"\"### Instruction:\n",
        "You are a helpful medical assistant. Answer clearly and safely.\n",
        "\n",
        "### Question:\n",
        "{q}\n",
        "\n",
        "### Answer:\n",
        "\"\"\"\n",
        "    inputs = tokenizer([prompt], return_tensors=\"pt\").to(\"cuda\")\n",
        "    out = model.generate(**inputs, max_new_tokens=180, do_sample=True, temperature=0.7)\n",
        "    print(tokenizer.decode(out[0], skip_special_tokens=True))\n",
        "\n",
        "ask(\"What is the difference between type 1 and type 2 diabetes?\")\n",
        "ask(\"When should someone seek urgent care for high blood pressure?\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MC5o7uKo7yD0",
        "outputId": "5fd10efb-6e4d-4e2d-c918-3be6ee6e40d9"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Instruction:\n",
            "You are a helpful medical assistant. Answer clearly and safely.\n",
            "\n",
            "### Question:\n",
            "What is the difference between type 1 and type 2 diabetes?\n",
            "\n",
            "### Answer:\n",
            "Type 1 diabetes is an autoimmune disease in which the body's immune system destroys the cells in the pancreas that make insulin. In type 2 diabetes, the body either doesn't produce enough insulin or the insulin that is made doesn't work as it should. These two types of diabetes are not the same, but they are both serious diseases that can cause complications if left untreated. Type 1 diabetes usually begins in childhood or adolescence, but can occur at any age. Type 2 diabetes is more common and usually begins in middle age or later.  The two types of diabetes are similar in that they both require regular monitoring of blood glucose levels and often medications to help control blood glucose levels. Both types of diabetes can lead to serious complications if left untreated. However, the treatment for type 1 diabetes is different than the treatment for type 2 diabetes. People with type 1 diabetes need\n",
            "### Instruction:\n",
            "You are a helpful medical assistant. Answer clearly and safely.\n",
            "\n",
            "### Question:\n",
            "When should someone seek urgent care for high blood pressure?\n",
            "\n",
            "### Answer:\n",
            "If you have high blood pressure, you should see your doctor right away. Your doctor can check to see if your blood pressure is too high and can recommend treatments.  If you have high blood pressure and other health problems, like heart disease, diabetes, or stroke, you should see your doctor right away.  You should also see your doctor if you have high blood pressure and you feel sick or are having problems with your heart.  You should also see your doctor if you are pregnant and have high blood pressure.  If you have a high blood pressure emergency, such as a heart attack, stroke, or severe headache, call 911 or your local emergency number right away.  If you have high blood pressure and you are having trouble breathing, you should go to the emergency room right away.  If you have high blood pressure and you have had a heart attack, stroke, or severe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "\n",
        "max_seq_length = 1024\n",
        "\n",
        "# 1) Load base model ONLY (no LoRA)\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=\"unsloth/llama-3.2-3b-bnb-4bit\",  #\n",
        "    max_seq_length=max_seq_length,\n",
        "    load_in_4bit=True,\n",
        ")\n",
        "\n",
        "FastLanguageModel.for_inference(model)\n",
        "\n",
        "def ask_base(q):\n",
        "    prompt = f\"\"\"### Instruction:\n",
        "You are a helpful medical assistant. Answer clearly and safely.\n",
        "\n",
        "### Question:\n",
        "{q}\n",
        "\n",
        "### Answer:\n",
        "\"\"\"\n",
        "    inputs = tokenizer([prompt], return_tensors=\"pt\").to(\"cuda\")\n",
        "    out = model.generate(**inputs, max_new_tokens=180, do_sample=True, temperature=0.7)\n",
        "    return tokenizer.decode(out[0], skip_special_tokens=True)\n",
        "\n",
        "# جرّبي نفس السؤال اللي بدك تقارني فيه\n",
        "q = \"What causes glaucoma?\"\n",
        "base_answer = ask_base(q)\n",
        "print(\"=== BEFORE (BASE) ===\")\n",
        "print(base_answer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBxO4prc9DPt",
        "outputId": "15193355-d83f-4ffc-c36b-9018c90bba70"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2026.1.4: Fast Llama patching. Transformers: 4.57.6.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.9.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.5.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = None. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "=== BEFORE (BASE) ===\n",
            "### Instruction:\n",
            "You are a helpful medical assistant. Answer clearly and safely.\n",
            "\n",
            "### Question:\n",
            "What causes glaucoma?\n",
            "\n",
            "### Answer:\n",
            "There are many causes of glaucoma, but one of the most common causes is elevated eye pressure. If the pressure in your eyes is too high, it can damage your optic nerve, which is the nerve that carries signals from your eyes to your brain. If the pressure is too high for too long, it can cause glaucoma. Other causes of glaucoma include aging, genetics, and eye surgery.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Olv5VEtw4Hk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastLanguageModel\n",
        "\n",
        "# 2) Attach LoRA structure then load adapter weights\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r=16,\n",
        "    target_modules=[\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\",\"gate_proj\",\"up_proj\",\"down_proj\"],\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0,\n",
        "    bias=\"none\",\n",
        "    use_gradient_checkpointing=\"unsloth\",\n",
        ")\n",
        "\n",
        "# Load your saved adapter folder\n",
        "model.load_adapter(\"medquad_lora\", adapter_name=\"medquad\")\n",
        "model.set_adapter(\"medquad\")   # تفعيل الأدابتر\n",
        "\n",
        "FastLanguageModel.for_inference(model)\n",
        "\n",
        "def ask_lora(q):\n",
        "    prompt = f\"\"\"### Instruction:\n",
        "You are a helpful medical assistant. Answer clearly and safely.\n",
        "\n",
        "### Question:\n",
        "{q}\n",
        "\n",
        "### Answer:\n",
        "\"\"\"\n",
        "    inputs = tokenizer([prompt], return_tensors=\"pt\").to(\"cuda\")\n",
        "    out = model.generate(**inputs, max_new_tokens=180, do_sample=True, temperature=0.7)\n",
        "    return tokenizer.decode(out[0], skip_special_tokens=True)\n",
        "\n",
        "lora_answer = ask_lora(q)\n",
        "print(\"=== AFTER (LoRA) ===\")\n",
        "print(lora_answer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6LXN_tR9OeF",
        "outputId": "fffb3a67-d482-4355-b789-7584f1e229d3"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== AFTER (LoRA) ===\n",
            "### Instruction:\n",
            "You are a helpful medical assistant. Answer clearly and safely.\n",
            "\n",
            "### Question:\n",
            "What causes glaucoma?\n",
            "\n",
            "### Answer:\n",
            "The exact cause of glaucoma is unknown. But it is clear that both genetic and environmental factors play a role. Many people with glaucoma have a family history of the disease. In some people, there is a strong genetic component to the development of glaucoma. Other people with glaucoma have no family history of the disease. It is likely that there are many genes involved in glaucoma. These genes work together to determine whether a person will develop glaucoma. Researchers are studying the genetic and environmental factors involved in the development of glaucoma. They hope to better understand the risk factors and develop new treatments. The following risk factors may increase the chances of developing glaucoma:  - Age. As you get older, your risk of developing glaucoma increases.  - Race. The risk of developing glaucoma is higher in people of African, Mexican\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\\n========================\")\n",
        "print(\"QUESTION:\", q)\n",
        "print(\"========================\\n\")\n",
        "\n",
        "print(\"BEFORE (BASE):\\n\", base_answer[:1200])\n",
        "print(\"\\n------------------------\\n\")\n",
        "print(\"AFTER (LoRA):\\n\", lora_answer[:1200])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJooCfGo9ySu",
        "outputId": "cc1649fa-0bf0-4f8d-dc20-5b93b128a89f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "========================\n",
            "QUESTION: What causes glaucoma?\n",
            "========================\n",
            "\n",
            "BEFORE (BASE):\n",
            " ### Instruction:\n",
            "You are a helpful medical assistant. Answer clearly and safely.\n",
            "\n",
            "### Question:\n",
            "What causes glaucoma?\n",
            "\n",
            "### Answer:\n",
            "There are many causes of glaucoma, but one of the most common causes is elevated eye pressure. If the pressure in your eyes is too high, it can damage your optic nerve, which is the nerve that carries signals from your eyes to your brain. If the pressure is too high for too long, it can cause glaucoma. Other causes of glaucoma include aging, genetics, and eye surgery.\n",
            "\n",
            "------------------------\n",
            "\n",
            "AFTER (LoRA):\n",
            " ### Instruction:\n",
            "You are a helpful medical assistant. Answer clearly and safely.\n",
            "\n",
            "### Question:\n",
            "What causes glaucoma?\n",
            "\n",
            "### Answer:\n",
            "The exact cause of glaucoma is unknown. But it is clear that both genetic and environmental factors play a role. Many people with glaucoma have a family history of the disease. In some people, there is a strong genetic component to the development of glaucoma. Other people with glaucoma have no family history of the disease. It is likely that there are many genes involved in glaucoma. These genes work together to determine whether a person will develop glaucoma. Researchers are studying the genetic and environmental factors involved in the development of glaucoma. They hope to better understand the risk factors and develop new treatments. The following risk factors may increase the chances of developing glaucoma:  - Age. As you get older, your risk of developing glaucoma increases.  - Race. The risk of developing glaucoma is higher in people of African, Mexican\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = [\n",
        "  \"What is hypertension?\",\n",
        "  \"What are symptoms of diabetes?\",\n",
        "  \"When should someone seek urgent care for high blood pressure?\",\n",
        "  \"What causes migraine headaches?\"\n",
        "]\n",
        "\n",
        "for q in question:\n",
        "    print(\"\\n====================\")\n",
        "    print(\"Q:\", q)\n",
        "    print(\"AFTER (LoRA):\")\n",
        "    print(ask_lora(q)[:800])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSleLe5D-C8S",
        "outputId": "77fae1a0-2006-4b94-df4e-066845aa4731"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====================\n",
            "Q: What is hypertension?\n",
            "AFTER (LoRA):\n",
            "### Instruction:\n",
            "You are a helpful medical assistant. Answer clearly and safely.\n",
            "\n",
            "### Question:\n",
            "What is hypertension?\n",
            "\n",
            "### Answer:\n",
            "Hypertension is a condition in which the blood pressure in the arteries is higher than it should be. High blood pressure is a major risk factor for heart disease and stroke. It can also cause damage to organs, such as the heart, kidneys, and eyes. Hypertension is also called the silent killer because it often has no symptoms and is not diagnosed until blood pressure is checked.  High blood pressure is usually caused by a combination of factors, including genetics, age, obesity, diet, and physical inactivity.  To diagnose hypertension, a healthcare provider will check your blood pressure. If your blood pressure is higher than normal, you may have hypertension. I\n",
            "\n",
            "====================\n",
            "Q: What are symptoms of diabetes?\n",
            "AFTER (LoRA):\n",
            "### Instruction:\n",
            "You are a helpful medical assistant. Answer clearly and safely.\n",
            "\n",
            "### Question:\n",
            "What are symptoms of diabetes?\n",
            "\n",
            "### Answer:\n",
            "Diabetes can cause a variety of symptoms. The symptoms of diabetes depend on the type of diabetes and how well it is controlled. The most common symptoms of diabetes include:  * Increased thirst  * Increased hunger  * Frequent urination  * Weight loss  * Slow healing of cuts and wounds  * Nausea and vomiting  * Fatigue  * Blurred vision  * Headaches  * Dizziness  * Itching  * Tingling or numbness  * Skin problems  * Impotence  * Slow wound healing  * Slow growth in children  * Sexual problems in women  * Slow-healing sores  * Recurrent infections  * Slow-healing cuts and wounds  * Skin infections  * Slow-healing sores  * Recurrent infections  * Slow-he\n",
            "\n",
            "====================\n",
            "Q: When should someone seek urgent care for high blood pressure?\n",
            "AFTER (LoRA):\n",
            "### Instruction:\n",
            "You are a helpful medical assistant. Answer clearly and safely.\n",
            "\n",
            "### Question:\n",
            "When should someone seek urgent care for high blood pressure?\n",
            "\n",
            "### Answer:\n",
            "If you have high blood pressure (hypertension), you should seek urgent care if you experience any of the following:   - chest pain or discomfort, shortness of breath, or lightheadedness.   - dizziness or loss of consciousness.   - vision changes.   - difficulty with urination.   - numbness or tingling in the hands or feet.   - shortness of breath.   - sudden headache.   - swelling in the ankles, legs, or face.   - unexplained weight gain.   - persistent vomiting.   - weakness or muscle cramps.   - confusion or memory loss.   - difficulty falling asleep or staying asleep.   - unexplained fatigue.   - severe headache.   - s\n",
            "\n",
            "====================\n",
            "Q: What causes migraine headaches?\n",
            "AFTER (LoRA):\n",
            "### Instruction:\n",
            "You are a helpful medical assistant. Answer clearly and safely.\n",
            "\n",
            "### Question:\n",
            "What causes migraine headaches?\n",
            "\n",
            "### Answer:\n",
            "Researchers are not sure what causes migraine headaches. They do know that the condition is likely related to brain chemistry. Some migraine triggers include hormonal changes, stress, bright lights and loud noises, changes in the weather, certain foods, and certain drugs. Some people are more likely to have migraine attacks than others, and there is no cure for migraine headaches.  Some people who have migraines can reduce their number of attacks by taking preventive medications. If you have frequent migraine headaches, you should talk to your doctor about preventive medications. Your doctor can also help you learn what steps to take to prevent migrai\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random.seed(42)\n",
        "\n",
        "for i in range(5):\n",
        "    sample = test_ds[random.randint(0, len(test_ds)-1)][\"text\"]\n",
        "\n",
        "    q = sample.split(\"### Question:\")[1].split(\"### Answer:\")[0].strip()\n",
        "\n",
        "    print(\"\\n====================\")\n",
        "    print(\"Q:\", q)\n",
        "    print(\"AFTER (LoRA):\")\n",
        "    print(ask_lora(q)[:700])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_UhBa7w-QiW",
        "outputId": "7f0ad45b-0fb1-4262-f3bf-6778cc795fbd"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====================\n",
            "Q: How to diagnose Harlequin ichthyosis ?\n",
            "AFTER (LoRA):\n",
            "### Instruction:\n",
            "You are a helpful medical assistant. Answer clearly and safely.\n",
            "\n",
            "### Question:\n",
            "How to diagnose Harlequin ichthyosis?\n",
            "\n",
            "### Answer:\n",
            "Harlequin ichthyosis is a rare, life-threatening condition that can be diagnosed in the first few days of life. It is a skin disorder caused by a mutation in the ABCA12 gene. This gene provides instructions for making an enzyme that helps the skin cells form a protective barrier. The diagnosis of harlequin ichthyosis is based on the characteristic pattern of skin lesions, which usually begin as large, waxy, yellowish-brown bumps that resemble boils. These lesions may be present at birth or appear within the first few days of life. The lesions beco\n",
            "\n",
            "====================\n",
            "Q: What is (are) Severe intellectual disability-progressive spastic diplegia syndrome ?\n",
            "AFTER (LoRA):\n",
            "### Instruction:\n",
            "You are a helpful medical assistant. Answer clearly and safely.\n",
            "\n",
            "### Question:\n",
            "What is (are) Severe intellectual disability-progressive spastic diplegia syndrome?\n",
            "\n",
            "### Answer:\n",
            "Severe intellectual disability-progressive spastic diplegia syndrome is a condition that is characterized by severe intellectual disability (IQ below 20), muscle stiffness (spasticity), and progressive weakness in the legs (diplegia) that worsens with age. Other features include seizures, difficulty swallowing (dysphagia), and drooling. Individuals with this condition typically have a normal life span. The condition is caused by mutations in the SLC16A2 gene. This condition is inherited in an autosomal\n",
            "\n",
            "====================\n",
            "Q: What are the symptoms of Congenital laryngeal palsy ?\n",
            "AFTER (LoRA):\n",
            "### Instruction:\n",
            "You are a helpful medical assistant. Answer clearly and safely.\n",
            "\n",
            "### Question:\n",
            "What are the symptoms of Congenital laryngeal palsy?\n",
            "\n",
            "### Answer:\n",
            "Congenital laryngeal palsy is a condition that causes paralysis of the muscles of the larynx. The symptoms of this condition vary depending on the specific type of laryngeal palsy. These include difficulty breathing, snoring, a weak voice, and an inability to speak clearly. Most cases of laryngeal palsy are mild and do not require treatment. However, severe cases may require surgery.  There are several types of laryngeal palsy. The most common type is unilateral vocal fold palsy, which causes weakness or paralysis of one side of the\n",
            "\n",
            "====================\n",
            "Q: What is (are) Lung Diseases ?\n",
            "AFTER (LoRA):\n",
            "### Instruction:\n",
            "You are a helpful medical assistant. Answer clearly and safely.\n",
            "\n",
            "### Question:\n",
            "What is (are) Lung Diseases?\n",
            "\n",
            "### Answer:\n",
            "The National Heart, Lung, and Blood Institute (NHLBI) conducts and supports research on the causes of lung diseases and the development of better diagnostic and treatment methods. NHLBI researchers also work to reduce the burden of lung diseases on the public health of the United States and to improve the quality of life for people with lung diseases. NHLBI funds a wide range of research that includes studies of the causes and prevention of lung diseases, and the development of new diagnostic and treatment methods. These studies are aimed at helping people\n",
            "\n",
            "====================\n",
            "Q: Is glycine encephalopathy inherited ?\n",
            "AFTER (LoRA):\n",
            "### Instruction:\n",
            "You are a helpful medical assistant. Answer clearly and safely.\n",
            "\n",
            "### Question:\n",
            "Is glycine encephalopathy inherited?\n",
            "\n",
            "### Answer:\n",
            "Glycine encephalopathy is inherited in an autosomal recessive manner. This means that two copies of the gene in each cell are altered, one from each parent. In most cases, a person inherits one altered copy of the gene from each parent. This can lead to an increased risk of developing the condition in future generations. The condition is rare, so it is unlikely that both parents are carriers of the altered gene.  Rarely, a person may be a mosaic, which means that they have only one copy of the altered gene in each cell. Mosaicism may result from th\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xa9HquPEEn1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc, torch\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "id": "eVDJfsOR0zwZ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "FastLanguageModel.for_inference(model)\n",
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"What is (are) Glaucoma?\", # Question\n",
        "        \"\", # Leave answer blank for the AI to fill\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 128)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rfgqfU_DJIn",
        "outputId": "972d9f66-fd4c-48fc-bc06-2c2cffb7e083"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nYou are a Clinical Data Specialist. Provide a technical summary from the MedQuAD dataset for the medical inquiry below.\\n\\n### Question:\\nWhat is (are) Glaucoma?\\n\\n### Answer:\\nGlaucoma is a group of eye diseases that cause damage to the optic nerve, which is the nerve that carries visual information from the eye to the brain. The most common type of glaucoma is primary open-angle glaucoma, which is the leading cause of blindness in the United States. Glaucoma is a progressive disease, which means that it gets worse over time. There are several types of glaucoma, and each type has its own specific symptoms and treatments. If you have glaucoma, you will need to see an eye doctor regularly to monitor your condition and receive treatment.\\n\\n### Explanation:\\nGlaucoma is']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Define the \"Personality\" of your AI (The Prompt)\n",
        "alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "You are a Clinical Data Specialist. Provide a technical summary from the MedQuAD dataset for the medical inquiry below.\n",
        "\n",
        "### Question:\n",
        "{}\n",
        "\n",
        "### Answer:\n",
        "{}\"\"\"\n",
        "\n",
        "# 2. Format your question\n",
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"What are the symptoms of Diabetes?\", # You can change this to any medical question!\n",
        "        \"\",\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "# 3. Generate the answer with a professional \"word-by-word\" look\n",
        "from transformers import TextStreamer\n",
        "text_streamer = TextStreamer(tokenizer)\n",
        "\n",
        "print(\"--- AI RESPONSE START ---\")\n",
        "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 256, repetition_penalty = 1.2)\n",
        "print(\"--- AI RESPONSE END ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phLBDyiv9H_V",
        "outputId": "01a1b74b-9c2b-4380-89c6-5a915308b036"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- AI RESPONSE START ---\n",
            "<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "You are a Clinical Data Specialist. Provide a technical summary from the MedQuAD dataset for the medical inquiry below.\n",
            "\n",
            "### Question:\n",
            "What are the symptoms of Diabetes?\n",
            "\n",
            "### Answer:\n",
            "The following table shows how many patients have diabetes and their respective symptom scores based on 10 questions asked by clinicians to assess disease severity:\n",
            "\n",
            "| Symptom Score | Number of Patients |\n",
            "|:------------:|:------------------|\n",
            "|   <font color='green'>0</font>     |          3         |\n",
            "|      <font color='#FF0000'>&lt;1</font>|           4        |\n",
            "\n",
            "---\n",
            "\n",
            "## Explanation\n",
            "\n",
            "This information can be used in conjunction with other clinical data sources such as electronic health records (EHRs) or patient-reported outcomes (PROs). For instance, one could use this type of analysis alongside EHR data to identify potential risk factors associated with developing diabetes among individuals who report experiencing certain types of symptoms. Alternatively, PRO data might provide insight into what aspects of daily life may contribute most significantly towards increasing someone’s likelihood of contracting Type II Diabetes over time.\n",
            "\n",
            "---\n",
            "\n",
            "#### References\n",
            "[1] National Institute of Health - \"Medquad Dataset\" [Online]. Available at https://www.nih.gov/research-funding/data-repositories/med-quac-dataset#:~:text=The%20MEDQUAC%2C%20which%20stands,%22Clinical%20Trials%20Database<|end_of_text|>\n",
            "--- AI RESPONSE END ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 🩺 Clinical AI Assistant Demo\n",
        "# @markdown Type a medical question here and press the play button on the left!\n",
        "\n",
        "User_Question = \"What are the complications of untreated Glaucoma?\" # @param {type:\"string\"}\n",
        "\n",
        "# This uses the prompt format we trained the model on\n",
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        User_Question,\n",
        "        \"\",\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "from transformers import TextStreamer\n",
        "text_streamer = TextStreamer(tokenizer)\n",
        "\n",
        "print(f\"--- ANALYZING: {User_Question} ---\")\n",
        "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 512, repetition_penalty = 1.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bChs8Rj9_fA",
        "outputId": "1dc28c26-deab-4ae5-d5bd-7acb718db061"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- ANALYZING: What are the complications of untreated Glaucoma? ---\n",
            "<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "You are a Clinical Data Specialist. Provide a technical summary from the MedQuAD dataset for the medical inquiry below.\n",
            "\n",
            "### Question:\n",
            "What are the complications of untreated Glaucoma?\n",
            "\n",
            "### Answer:\n",
            "Glaucoma can lead to severe vision loss or blindness if left untreated and may require surgery. However, there are medications available today that help prevent glaucomatous damage by lowering intraocular pressure (IOP). These include prostaglandin analogs such as bimatoprost, travoprost, latanoprost, and tafluprost; alpha-adrenergic agonists like brimonidine tartrate and apraclonidine hydrochloride; carbonic anhydrase inhibitors like dorzolamide hydrochloride and brinzolamide; and beta-blockers like timolol maleate. In addition to these treatments, other therapies have been developed over time including laser trabeculoplasty which uses lasers to open up the drainage angle in order to lower IOP levels more effectively than medication alone could do so without having any side effects associated with them being used together at once - however this procedure only works temporarily because eventually all patients will need additional therapy regardless whether they receive one type treatment versus another depending upon what their individual needs happen too be throughout course disease progression stage wise mannerly speaking thus far though fortunately enough now days many different options exist when it comes down selecting best possible approach based off current condition status quo regarding severity level plus duration amount time period since initial diagnosis occurred originally back then way yesteryear ago long past before present tense right here presently moment right now instantaneously within space-time continuum universal existence realm encompassing entire universe everything contained therein eternally forevermore unto eternity beyond death end point final frontier ultimate destination last stop on road trip through life journey across infinite expanse unknown vastness uncharted territory undiscovered country untamed wilderness wild west lawless land where good guys wear white hats bad guy wears black hat shoot fast draw quick aim true shot hit bullseye every single time no excuses misses hits never fails always strikes dead center target first try second third fourth fifth sixth seventh eighth ninth tenth eleventh twelfth thirteenth fourteenth fifteenth sixteenth seventeenth eighteenth nineteenth twentieth twenty-first twenty-second twenty-third twenty-fourth twenty-fifth twenty-sixth twenty-seventh twenty-eighth twenty-ninth thirty-thirty-one forty-two fifty-five sixty-seven seventy-nine eighty-eight ninety-three hundred thousand billion trillion quadrillion sextillion octillion nonillion decillion centillion googolplex googols zillions billions trillions gazillions millionaires quinquillions squads hordes myriads hundreds thousands millions billions trillion quadrillions quintillions sextillions septillions octillions novemillions duodec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Create a zip file containing the model folder and the dataset\n",
        "# !zip -r [name_of_zip] [folder_to_zip] [other_files]\n",
        "!zip -r Medical_AI_Project.zip drive/MyDrive/medical_model_lora medquad.csv\n",
        "\n",
        "print(\"Zip file created successfully! Look for Medical_AI_Project.zip in the left sidebar.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yy4YIbJgEq5k",
        "outputId": "61f4740a-2fac-43df-fe27-b83150c3f4de"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tzip warning: name not matched: drive/MyDrive/medical_model_lora\n",
            "  adding: medquad.csv (deflated 78%)\n",
            "Zip file created successfully! Look for Medical_AI_Project.zip in the left sidebar.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Create the zip folder containing ALL components\n",
        "# This includes: your trained model, the dataset, and any output files\n",
        "!zip -r Medical_AI_Complete_Project.zip drive/MyDrive/medical_model_lora medquad.csv\n",
        "\n",
        "print(\"Full project zipped! Now download 'Medical_AI_Complete_Project.zip' from the sidebar.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrp1F-3bFgF0",
        "outputId": "b30c1426-d8b9-46fc-958c-b3d938d69e65"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tzip warning: name not matched: drive/MyDrive/medical_model_lora\n",
            "  adding: medquad.csv (deflated 78%)\n",
            "Full project zipped! Now download 'Medical_AI_Complete_Project.zip' from the sidebar.\n"
          ]
        }
      ]
    }
  ]
}